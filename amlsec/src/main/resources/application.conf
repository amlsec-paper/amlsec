baseDir = ${user.home}"/amlsec/"
amlToOwlProgram = ${user.home}"/amlsec/aml_owl-0.0.1-SNAPSHOT-jar-with-dependencies.jar"
# Jena reasoner setting, for enhanced performance use the Jena's micro reasoner
## "http://jena.hpl.hp.com/2003/OWLMicroFBRuleReasoner"
## "http://jena.hpl.hp.com/2003/OWLFBRuleReasoner"
reasonerUri = "http://jena.hpl.hp.com/2003/OWLMicroFBRuleReasoner"

aml {
  filePath = ${user.home}"/amlsec/quality-case-study/A/CaseStudy_A.aml"
  # Deprecated now, since AML-to-OWL transformation is directly embedded into the method execution
  # However, this setting can still be activated for debugging purposes (e.g., to run the method without Akka)
  # ontFilePath = ${user.home}"/amlsec/engineering_data_representation_aml.ttl"
  nsOnt = "http://www.ipr.kit.edu/aml_ontology"
  nsImp = "http://www.ipr.kit.edu/aml_importer"
}

secOnt {
  filePath = ${user.home}"/amlsec/ontologies/security-ontology.owl"
  ns = "http://securityontology.com/secont"
}

icsSecOnt {
  filePath = ${user.home}"/amlsec/ontologies/ics-security-ontology.owl"
  ns = "http://securityontology.com/icssecont"
}

agOnt {
  filePath = ${user.home}"/amlsec/ontologies/ag-ontology.owl"
  ns = "http://securityontology.com/agont"
}

qualityOnt {
    filePath = ${user.home}"/amlsec/ontologies/quality-ontology.owl"
    ns = "http://www.qualityontology.org"
}

sfc {

    sfcFilePath = ${user.home}"/amlsec/quality-case-study/A/plc.xml"

    ontoPlc {
        filePath = ${user.home}"/amlsec/ontologies/OntoPLC.owl"
        ns = "http://www.semanticweb.org/aym/ontologies/2019/3/untitled-ontology-407"
    }

    sfcTransformationOnt {
        ns = "https://sba-research.org/sfctransformation"
    }

}

validation {
  eng.filePath = ${user.home}"/amlsec/rules/engineering_data_validation_rules.ttl"
  sec.filePath = ${user.home}"/amlsec/rules/security_vulnerabilities_rules.ttl"
}

outputPathEngValReport = ${user.home}"/amlsec/reports/report_eng_val.ttl"
outputPathSecValReport = ${user.home}"/amlsec/reports/report_sec_val.ttl"

ag {
  full.path = ${user.home}"/amlsec/full_ag.svg"
  pruned.path = ${user.home}"/amlsec/pruned_ag.svg"
  shortestPath.path = ${user.home}"/amlsec/shortest_path_ag.svg"
}

qopn {
    lola {
        filePath = ${user.home}"/amlsec/qopn.lola"
        stateFilePath = ${user.home}"/amlsec/lola_state.txt"
        pathFilePath = ${user.home}"/amlsec/lola_path.txt"
        outputFilePath = ${user.home}"/amlsec/lola_output.txt"
    }

    pnml.filePath = ${user.home}"/amlsec/qopn.pnml"
}

debug {
    kb {
        writeKb = true
        outputPathAmlsecKb = ${user.home}"/amlsec/amlsec_kb.ttl"
    }

    performance {
        writePerformanceReport = true
        outputPathPerformanceReport = ${user.home}"/amlsec/performance_report.txt"
    }
}

akka {
  actor {
    # Must be set like this to use Akka Cluster
    provider = cluster
    serialization-bindings {
      "org.sba_research.worker.CborSerializable" = jackson-cbor
    }
    debug.lifecycle = on
  }

  # filtered further in logback.xml
  loglevel = "DEBUG"

  # Maximum serialized message size, including header data.
  # Increased this value, since validation reports can get pretty large with a big AML artifact
  # In the future, we should store the validation reports in a database and only send notifications of the pubsub channel
  remote.artery.advanced.maximum-frame-size =  31250 KiB #256 KiB

  remote.artery.canonical {
    hostname = "127.0.0.1"
    # overriden in the main method
    port = 2551
  }

  cluster {
    # Seed nodes are a way to have a node join the cluster (or form a new cluster) from configuration.
    seed-nodes = [
      "akka://ClusterSystem@127.0.0.1:2551",
      "akka://ClusterSystem@127.0.0.1:3000"
      ]

    # Needed when running many actor systems in the same JVM
    jmx.multi-mbeans-in-same-jvm = on

    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"

    failure-detector.acceptable-heartbeat-pause = 10s
  }

  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "cassandra-journal"
    snapshot-store.plugin = "cassandra-snapshot-store"
  }

  # Run the pubsub mediator on all nodes, without any code starting it up
  extensions = ["akka.cluster.pubsub.DistributedPubSub"]

  pub-sub {
      # Actor name of the mediator actor, /system/distributedPubSubMediator
      name = distributedPubSubMediator

      # Start the mediator on members tagged with this role.
      # All members are used if undefined or empty.
      role = ""

      # The routing logic to use for 'Send'
      # Possible values: random, round-robin, broadcast
      routing-logic = random

      # How often the DistributedPubSubMediator should send out gossip information
      gossip-interval = 1s

      # Removed entries are pruned after this duration
      removed-time-to-live = 120s

      # Maximum number of elements to transfer in one message when synchronizing the registries.
      # Next chunk will be transferred in next round of gossip.
      max-delta-elements = 3000

      # When a message is published to a topic with no subscribers send it to the dead letters.
      send-to-dead-letters-when-no-subscribers = on

      # The id of the dispatcher to use for DistributedPubSubMediator actors.
      # If specified you need to define the settings of the actual dispatcher.
      use-dispatcher = "akka.actor.internal-dispatcher"
  }

    # Ask timeout for sending message to worker until receiving Ack from worker
    # Increased this timeout from 60s to 10m for long-running work items (otherwise confirmation to work manager leads to dead-letters)
    reliable-delivery.work-pulling.producer-controller.internal-ask-timeout = 10m

}

# Configuration related to the app is in its own namespace
distributed-workers {
  # If a workload hasn't finished in this long it
  # is considered failed and is retried
  work-timeout = 10s

  # Timeout for worker waiting for ack from work manager
  work-ack-timeout = 5s
}

fuseki {
    tdbDir = "target/fuseki-db/"
    uri = "http://localhost:3030"
}
